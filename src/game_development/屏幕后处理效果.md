## 屏幕后处理效果

### 调整屏幕的亮度、饱和度和对比度

这一部分的逻辑比较简单，就是按照一定的规律调整RGB值。

```cpp
#iChannel0 "file://sakura0.jpg"

float brightness = 1.0; // 亮度
float saturation = 1.0; // 饱和度
float contrast = 1.0; // 对比度

void mainImage(out vec4 fragColor, in vec2 fragCoord){
    vec2 uv = fragCoord.xy / iResolution.xy;
    vec4 textureColor = texture(iChannel0, uv);
    
    // 亮度
    vec3 finalColor = textureColor.rgb * brightness;
    
    // 饱和度
    float luminance = 0.2125*textureColor.r + 0.7154*textureColor.g + 0.0721*textureColor.b;
    vec3 luminanceColor = vec3(luminance);
    finalColor = mix(luminanceColor, finalColor, saturation);
    
    // 对比度    
    vec3 avgColor = vec3(0.5,0.5,0.5);
    finalColor = mix(avgColor,finalColor,contrast);

    fragColor = vec4(finalColor,textureColor.a);
}
```

### 边缘检测

在图像处理中，卷积操作指的是使用一个卷积核对一张图像中的每个像素进行一系列操作。卷积核通常是一个四方形网格结构，该区域内每个方格都有一个权重值。当对图像中的某个像素进行卷积时，我们会把卷积核的中心放置于该像素上，翻转核之后再依次计算核中每个元素和其覆盖的图像像素值的乘积并求和，得到的结果就是该位置的新像素值。

如果相邻像素之间存在差别明显的颜色、亮度、纹理等属性，我们就会认为它们之间应该有一条边界。这种相邻像素之间的差值可以用梯度来表示，可以想象，边缘处的梯度值会比较大。基于这样的理解，有几种不同的边缘检测算子先后被提出来。

- Roberts

$$
\left[\begin{matrix}
   -1 & 0 \\
   0 & 1 
\end{matrix}\right]
\left[\begin{matrix}
   0 & -1 \\
   1 & 0 
\end{matrix}\right]
$$

- Prewitt

$$
\left[\begin{matrix}
   -1 & 0 & 1\\
   -1 & 0 & 1\\
   -1 & 0 & 1 
\end{matrix}\right]
\left[\begin{matrix}
   -1 & -1 & -1 \\
   0 & 0 & 0 \\
   1 & 1 & 1
\end{matrix}\right]
$$

- Sobel

$$
\left[\begin{matrix}
   -1 & 0 & 1\\
   -2 & 0 & 2\\
   -1 & 0 & 1 
\end{matrix}\right]
\left[\begin{matrix}
   -1 & -2 & -1 \\
   0 & 0 & 0 \\
   1 & 2 & 1
\end{matrix}\right]
$$

上面三种常见的边缘检测算子，他们都包含了两个方向的卷积核，分别用于检测水平方向和竖直方向上的边缘信息。在进行边缘检测时，我们需要对每个像素分别进行一次卷积计算，得到两个方向上的梯度值$$G_x$$和$$G_y$$，而整体的梯度可按下面的公式计算而得：

$$
G=\sqrt{G_x^2 + G_y^2}
$$

由于上述计算包含了开根号操作，出于性能的考虑，我们有时会使用绝对值操作来代替开根号操作：

$$
G=|G_x| + |G_y|
$$

得到梯度 G 后，我们可以根据此来判断哪些像素对应了边缘，梯度值越大，越有可能是边缘点。

```cpp
#iChannel0 "file://sakura0.jpg"

vec4 edgeColor = vec4(0.0,0.0,0.0,1.0);
vec4 bgColor = vec4(1.0);
float edgeOnly = 0.0;

float luminance(vec4 color){
    return 0.2125 * color.r + 0.7154 * color.g + 0.0721 * color.b;
}

float sobel(vec4 textureColors[9]){
    const float GX[9] = float[9](
        -1.0,-2.0,-1.0,
        0.0,0.0,0.0,
        1.0,2.0,1.0);
    const float GY[9] = float[9](
        -1.0,0.0,1.0,
        -2.0,0.0,2.0,
        -1.0,0.0,1.0);
    float edgeX = 0.0;
    float edgeY = 0.0;
    float textureColor;
    for(int i=0;i<9;i++){
        textureColor = luminance(textureColors[i]);
        edgeX += textureColor * GX[i];
        edgeY += textureColor * GY[i];
    }
    // edge值越大，该点越有可能是
    float edge = 1.0 - abs(edgeX) - abs(edgeY);
    return edge;
}

void main(){
    vec4 textureColors[9];
    // 计算相邻的纹理坐标
    vec2 firstPos = gl_FragCoord.xy - vec2(1.0,1.0);
    for(int i=0;i<9;i++){
        vec2 offset = vec2(i%3,i/3);
        vec2 uv = (firstPos + offset) / iResolution.xy;
        textureColors[i] = texture(iChannel0,uv);
    }
    float edge = sobel(textureColors);
    vec4 withEdgeColor = mix(edgeColor,textureColors[4],edge);
    vec4 onlyEdgeColor = mix(edgeColor,bgColor,edge);
    vec4 finalColor = mix(withEdgeColor,onlyEdgeColor,edgeOnly);
    gl_FragColor = finalColor;
}
```

### 高斯模糊

高斯模糊同样利用了卷积计算，它使用的卷积核名为高斯核。高斯核是一个正方形大小的滤波核，其中每个元素的计算都是基于下面的高斯方程：

$$
G(x,y) = \frac{1}{2\pi\sigma^2}e^{-\frac{x^2+y^2}{2^{\sigma^2}}}
$$

其中，$$\sigma$$是标准方差，一般取值为1，x 和 y 分别对应了当前位置到卷积核中心的整数距离。要构建一个高斯核，我们需要对高斯核中的权重进行归一化，即让每个权重除以所有权重的和，这样可以保证所有权重的和为 1。高斯方程很好地模拟领域内每个像素对当前处理像素的影响程度——距离越近，影响越大。

```cpp
#iChannel0 "file://sakura0.jpg"

const int kSize = (5 - 1)/2;
// 预计算得到的权重值
const float kernel[5] = float[5](0.0545,0.2442,0.4026,0.2442,0.0545);
const int blurSize = 2;

void mainImage(out vec4 fragColor, in vec2 fragCoord){
	vec4 color = vec4(0.0);
	for(int i=-kSize;i<=kSize;i++){
		for(int j=-kSize;j<=kSize;j++){
			// 采样相邻的像素
            vec2 offset = vec2(float(i*blurSize),float(j*blurSize));
			vec4 c = texture(iChannel0,(fragCoord.xy +  offset)/iResolution.xy);
			color +=  c * kernel[i + kSize] * kernel[j+kSize];
		}
	}
	fragColor = color;
}
```

### Bloom

Bloom 的实现原理非常简单：我们首先根据以一个阈值取出图像中的较亮区域，把它们存储在一张渲染纹理中，再利用高斯模糊对这张渲染纹理进行模糊处理，模拟光线扩散的效果，最后再将其和原图像进行混合，得到最终的效果。

```cpp
#iChannel0 "file://sakura1.jpg"

const int kSize = (5 - 1)/2;
// 预计算得到的权重值
const float kernel[5] = float[5](0.0545,0.2442,0.4026,0.2442,0.0545);
const int blurSize = 2;

float luminance(vec4 color){
    return 0.2125 * color.r + 0.7154 * color.g + 0.0721 * color.b;
}

vec4 getBlurColor(vec2 fragCoord){
    vec4 color = vec4(0.0);
	for(int i=-kSize;i<=kSize;i++){
		for(int j=-kSize;j<=kSize;j++){
			// 采样相邻的像素
            vec2 offset = vec2(float(i * blurSize),float(j * blurSize));
			vec4 c = texture(iChannel0,(fragCoord.xy + offset)/iResolution.xy);
			color +=  c * kernel[i + kSize] * kernel[j+kSize];
		}
	}
    float val = clamp(luminance(color) - 0.2,0.0,1.0);
    return color * val;
}

void mainImage(out vec4 fragColor, in vec2 fragCoord){
    vec4 color = texture(iChannel0,fragCoord.xy / iResolution.xy);
    vec4 blurColor = getBlurColor(fragCoord);
	fragColor = color + blurColor;
}
```

### 径向模糊

### 老式电影效果